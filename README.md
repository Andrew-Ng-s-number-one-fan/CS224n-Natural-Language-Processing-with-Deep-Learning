# [CS224n: Natural Language Processing with Deep Learning](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/)

### Lecture Videos (Winter 2019)

### Lecture 1:
|Description|Content|Suggested Readings|
|:---:|:---:|:---:|:---:|
|Introduction and Word Vectors|[[Video](https://www.youtube.com/watch?v=8rXD5-xhemo&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=1)] [[Slides]()] [[Notes]()]|

|#|Description|Content|Suggested Readings|
|Lecture 2|[Word Vectors and Word Senses](https://www.youtube.com/watch?v=kEMJRjEdNzM&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=2)|
|Lecture 3|[Neural Networks](https://www.youtube.com/watch?v=8CWyBNX6eDo&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=3)|
|Lecture 4|[Backpropagation](https://www.youtube.com/watch?v=yLYHDSv-288&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=4)|
|Lecture 5|[Dependency Parsing](https://www.youtube.com/watch?v=nC9_RfjYwqA&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=5)|
|Lecture 6|[Language Models and RNNs](https://www.youtube.com/watch?v=iWea12EAu6U&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=6)|
|Lecture 7|[Vanishing Gradients, Fancy RNNs](https://www.youtube.com/watch?v=QEw0qEa0E50&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=7)|
|Lecture 8|[Translation, Seq2Seq, Attention](https://www.youtube.com/watch?v=XXtpJxZBa2c&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=8)|
|Lecture 9|[Practical Tips for Projects](https://www.youtube.com/watch?v=fyqm8fRDgl0&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=9)|
|Lecture 10|[Question Answering](https://www.youtube.com/watch?v=yIdF-17HwSk&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=10)|
|Lecture 11|[Convolutional Networks for NLP](https://www.youtube.com/watch?v=EAJoRA0KX7I&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=11)|
|Lecture 12|[Subword Models](https://www.youtube.com/watch?v=9oTHFx0Gg3Q&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=12)|
|Lecture 13|[Contextual Word Embeddings](https://www.youtube.com/watch?v=S-CspeZ8FHc&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=13)|
|Lecture 14|[Transformers and Self-Attention](https://www.youtube.com/watch?v=5vcj8kSwBCY&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=14)|
|Lecture 15|[Natural Language Generation](https://www.youtube.com/watch?v=4uG1NMKNWCU&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=15)|
|Lecture 16|[Coreference Resolution](https://www.youtube.com/watch?v=i19m4GzBhfc&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=16)|
|Lecture 17|[Multi-task Learning](https://www.youtube.com/watch?v=M8dsZsEtEsg&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=17)|
|Lecture 18|[Constituency Parsing, TreeRNNs](https://www.youtube.com/watch?v=6Z4A3RSf-HY&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=18)|
|Lecture 19|[Bias in AI](https://www.youtube.com/watch?v=XR8YSRcuVLE&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=19)|
|Lecture 20|[Future of NLP + Deep Learning](https://www.youtube.com/watch?v=3wWZBGN-iX8&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=20)|
